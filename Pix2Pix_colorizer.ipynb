{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pix2Pix_colorizer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astridjerald/colorizer/blob/master/Pix2Pix_colorizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "y2DtaNhO_r6p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pix2Pix in Tensorflow"
      ]
    },
    {
      "metadata": {
        "id": "V2EW9qXK_r60",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "2-dZGyVnXKWj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bae2fb0d-29f3-4e0b-be63-c3eed5137d52"
      },
      "cell_type": "code",
      "source": [
        "#Import the libraries we will need.\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.contrib.slim as slim\n",
        "import os\n",
        "import scipy.misc\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "import os\n",
        "%matplotlib inline\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#Size of image frames\n",
        "height = 144\n",
        "width = 256"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "osxuzj6pDfD8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.misc\n",
        "import os\n",
        "import csv\n",
        "import itertools\n",
        "import tensorflow.contrib.slim as slim\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "#Generates gifs\n",
        "def make_gif(images, fname, duration=2, true_image=False):\n",
        "  import moviepy.editor as mpy\n",
        "  \n",
        "  def make_frame(t):\n",
        "    try:\n",
        "      x = images[int(len(images)/duration*t)]\n",
        "    except:\n",
        "      x = images[-1]\n",
        "\n",
        "    if true_image:\n",
        "      return x.astype(np.uint8)\n",
        "    else:\n",
        "      return ((x+1)/2*255).astype(np.uint8)\n",
        "  \n",
        "  clip = mpy.VideoClip(make_frame, duration=duration)\n",
        "  clip.write_gif(fname, fps = len(images) / duration,verbose=False)\n",
        "\n",
        "#Function loads images from list of files. bw_bool is True when the source images are originally greyscale and 4:3\n",
        "#Flip determines whether images should be flipped \n",
        "def loadImages(data,bw_bool,flip):\n",
        "    images = []\n",
        "    images_bw = []\n",
        "    if bw_bool == False:\n",
        "        for myFile in data:\n",
        "            img = Image.open(myFile)\n",
        "            bw = np.max(img,2)\n",
        "            bw = np.stack([bw,bw,bw],2)\n",
        "            bw[:,:40,:] = 0\n",
        "            bw[:,-40:,:] = 0\n",
        "            if flip == False:\n",
        "                images.append(np.array(img))\n",
        "                images_bw.append(bw)\n",
        "            else:\n",
        "                img_flip = np.fliplr(img)\n",
        "                images.append(img_flip)\n",
        "                bw_flip = np.fliplr(bw)\n",
        "                images_bw.append(bw_flip)\n",
        "        images = np.array(images)\n",
        "        images = images.astype('float32')\n",
        "        images = images / 256\n",
        "        images_bw = np.array(images_bw)\n",
        "        images_bw = images_bw.astype('float32')\n",
        "        images_bw = images_bw / 256\n",
        "        return images,images_bw\n",
        "    else:\n",
        "        for myFile in data:\n",
        "            img = Image.open(myFile)\n",
        "            bw = img.resize((196,144))\n",
        "            bw = np.max(bw,2)\n",
        "            bw = np.stack([bw,bw,bw],2)\n",
        "            bw_w = np.zeros([144,256,3])\n",
        "            bw_w[:,30:-30,:] = bw\n",
        "            bw_w[:,:40,:] = 0\n",
        "            bw_w[:,-40:,:] = 0\n",
        "        images.append(bw_w)\n",
        "        images = np.array(images)\n",
        "        images = images.astype('float32')\n",
        "        images = images / 256\n",
        "        return images\n",
        "\n",
        "#This function performns a leaky relu activation, which is needed for the discriminator network.\n",
        "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
        "     with tf.variable_scope(name):\n",
        "         f1 = 0.5 * (1 + leak)\n",
        "         f2 = 0.5 * (1 - leak)\n",
        "         return f1 * x + f2 * abs(x)\n",
        "    \n",
        "#The below functions are taken from carpdem20's implementation https://github.com/carpedm20/DCGAN-tensorflow\n",
        "#They allow for saving sample images from the generator to follow progress\n",
        "def save_images(images, size, image_path):\n",
        "    return imsave(inverse_transform(images), size, image_path)\n",
        "\n",
        "def imsave(images, size, path):\n",
        "    return scipy.misc.imsave(path, merge(images, size))\n",
        "\n",
        "def inverse_transform(images):\n",
        "    return (images+1.)/2.\n",
        "\n",
        "def merge(images, size):\n",
        "    h, w = images.shape[1], images.shape[2]\n",
        "    img = np.zeros((h * size[0], w * size[1],3))\n",
        "\n",
        "    for idx, image in enumerate(images):\n",
        "        i = idx % size[1]\n",
        "        j = idx / size[1]\n",
        "        img[j*h:j*h+h, i*w:i*w+w,:] = image\n",
        "\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nQR10iBsln9M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2611
        },
        "outputId": "09a81545-a432-4183-8272-e47160b69e3b"
      },
      "cell_type": "code",
      "source": [
        "data=loadImages(['/content/gdrive/My Drive/pix2pix_images/out0001.png'],False,False)\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "print(list(data))\n",
        "plt.imshow(data[0], interpolation='nearest')\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[[[0.        , 0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        ],\n",
            "         ...,\n",
            "         [0.        , 0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        ]],\n",
            "\n",
            "        [[0.        , 0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        ],\n",
            "         ...,\n",
            "         [0.        , 0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        ]],\n",
            "\n",
            "        [[0.        , 0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        ],\n",
            "         ...,\n",
            "         [0.        , 0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.        , 0.        , 0.0078125 ],\n",
            "         [0.        , 0.        , 0.0078125 ],\n",
            "         [0.        , 0.        , 0.0078125 ],\n",
            "         ...,\n",
            "         [0.        , 0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        ]],\n",
            "\n",
            "        [[0.        , 0.        , 0.0078125 ],\n",
            "         [0.        , 0.        , 0.0078125 ],\n",
            "         [0.        , 0.        , 0.0078125 ],\n",
            "         ...,\n",
            "         [0.00390625, 0.        , 0.        ],\n",
            "         [0.00390625, 0.        , 0.        ],\n",
            "         [0.00390625, 0.        , 0.        ]],\n",
            "\n",
            "        [[0.        , 0.        , 0.0078125 ],\n",
            "         [0.        , 0.        , 0.0078125 ],\n",
            "         [0.        , 0.        , 0.0078125 ],\n",
            "         ...,\n",
            "         [0.00390625, 0.        , 0.        ],\n",
            "         [0.00390625, 0.        , 0.        ],\n",
            "         [0.00390625, 0.        , 0.        ]]]], dtype=float32), array([[[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]]], dtype=float32)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-4a3b243b8ecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3210\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3211\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1867\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5499\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5501\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5502\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/image.pyc\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    644\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    645\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 646\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAAD8CAYAAABzYsGzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "1n6pA8pZ_r7L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Defining the Adversarial Networks"
      ]
    },
    {
      "metadata": {
        "id": "4-22BlHo_r7O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Generator Network"
      ]
    },
    {
      "metadata": {
        "id": "tyHppQou_r7R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator(c):\n",
        "    with tf.variable_scope('generator'):\n",
        "        #Encoder\n",
        "        enc0 = slim.conv2d(c,64,[3,3],padding=\"SAME\",\n",
        "            biases_initializer=None,activation_fn=lrelu,\n",
        "            weights_initializer=initializer)\n",
        "        enc0 = tf.space_to_depth(enc0,2)\n",
        "        \n",
        "        enc1 = slim.conv2d(enc0,128,[3,3],padding=\"SAME\",\n",
        "            activation_fn=lrelu,normalizer_fn=slim.batch_norm,\n",
        "            weights_initializer=initializer)\n",
        "        enc1 = tf.space_to_depth(enc1,2)\n",
        "\n",
        "        enc2 = slim.conv2d(enc1,128,[3,3],padding=\"SAME\",\n",
        "            normalizer_fn=slim.batch_norm,activation_fn=lrelu,\n",
        "            weights_initializer=initializer)\n",
        "        enc2 = tf.space_to_depth(enc2,2)\n",
        "\n",
        "        enc3 = slim.conv2d(enc2,256,[3,3],padding=\"SAME\",\n",
        "            normalizer_fn=slim.batch_norm,activation_fn=lrelu,\n",
        "            weights_initializer=initializer)\n",
        "        enc3 = tf.space_to_depth(enc3,2)\n",
        "        \n",
        "        #Decoder\n",
        "        gen0 = slim.conv2d(\n",
        "            enc3,num_outputs=256,kernel_size=[3,3],\n",
        "            padding=\"SAME\",normalizer_fn=slim.batch_norm,\n",
        "            activation_fn=tf.nn.elu, weights_initializer=initializer)\n",
        "        gen0 = tf.depth_to_space(gen0,2)\n",
        "\n",
        "        gen1 = slim.conv2d(\n",
        "            tf.concat([gen0,enc2],3),num_outputs=256,kernel_size=[3,3],\n",
        "            padding=\"SAME\",normalizer_fn=slim.batch_norm,\n",
        "            activation_fn=tf.nn.elu,weights_initializer=initializer)\n",
        "        gen1 = tf.depth_to_space(gen1,2)\n",
        "\n",
        "        gen2 = slim.conv2d(\n",
        "            tf.concat([gen1,enc1],3),num_outputs=128,kernel_size=[3,3],\n",
        "            padding=\"SAME\",normalizer_fn=slim.batch_norm,\n",
        "            activation_fn=tf.nn.elu,weights_initializer=initializer)\n",
        "        gen2 = tf.depth_to_space(gen2,2)\n",
        "\n",
        "        gen3 = slim.conv2d(\n",
        "            tf.concat([gen2,enc0],3),num_outputs=128,kernel_size=[3,3],\n",
        "            padding=\"SAME\",normalizer_fn=slim.batch_norm,\n",
        "            activation_fn=tf.nn.elu, weights_initializer=initializer)\n",
        "        gen3 = tf.depth_to_space(gen3,2)\n",
        "        \n",
        "        g_out = slim.conv2d(\n",
        "            gen3,num_outputs=3,kernel_size=[1,1],padding=\"SAME\",\n",
        "            biases_initializer=None,activation_fn=tf.nn.tanh,\n",
        "            weights_initializer=initializer)\n",
        "        return g_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fjhGD2UY_r7c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Discriminator Network"
      ]
    },
    {
      "metadata": {
        "id": "5k4YgX5L_r7f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def discriminator(bottom, reuse=False):\n",
        "    with tf.variable_scope('discriminator'):\n",
        "        filters = [32,64,128,128]\n",
        "        \n",
        "        #Programatically define layers\n",
        "        for i in range(len(filters)):\n",
        "            if i == 0:\n",
        "                layer = slim.conv2d(bottom,filters[i],[3,3],padding=\"SAME\",scope='d'+str(i),\n",
        "                    biases_initializer=None,activation_fn=lrelu,stride=[2,2],\n",
        "                    reuse=reuse,weights_initializer=initializer)\n",
        "            else:\n",
        "                layer = slim.conv2d(bottom,filters[i],[3,3],padding=\"SAME\",scope='d'+str(i),\n",
        "                    normalizer_fn=slim.batch_norm,activation_fn=lrelu,stride=[2,2],\n",
        "                    reuse=reuse,weights_initializer=initializer)\n",
        "            bottom = layer\n",
        "\n",
        "        dis_full = slim.fully_connected(slim.flatten(bottom),1024,activation_fn=lrelu,scope='dl',\n",
        "            reuse=reuse, weights_initializer=initializer)\n",
        "\n",
        "        d_out = slim.fully_connected(dis_full,1,activation_fn=tf.nn.sigmoid,scope='do',\n",
        "            reuse=reuse, weights_initializer=initializer)\n",
        "        return d_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZkBrVsnE_r7o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Connecting them together"
      ]
    },
    {
      "metadata": {
        "id": "s-dXwYEs_r7r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "#This initializaer is used to initialize all the weights of the network.\n",
        "initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
        "\n",
        "#\n",
        "condition_in = tf.placeholder(shape=[None,height,width,3],dtype=tf.float32)\n",
        "real_in = tf.placeholder(shape=[None,height,width,3],dtype=tf.float32) #Real images\n",
        "\n",
        "Gx = generator(condition_in) #Generates images from random z vectors\n",
        "Dx = discriminator(real_in) #Produces probabilities for real images\n",
        "Dg = discriminator(Gx,reuse=True) #Produces probabilities for generator images\n",
        "\n",
        "#These functions together define the optimization objective of the GAN.\n",
        "d_loss = -tf.reduce_mean(tf.log(Dx) + tf.log(1.-Dg)) #This optimizes the discriminator.\n",
        "#For generator we use traditional GAN objective as well as L1 loss\n",
        "g_loss = -tf.reduce_mean(tf.log(Dg)) + 100*tf.reduce_mean(tf.abs(Gx - real_in)) #This optimizes the generator.\n",
        "\n",
        "#The below code is responsible for applying gradient descent to update the GAN.\n",
        "trainerD = tf.train.AdamOptimizer(learning_rate=0.0002,beta1=0.5)\n",
        "trainerG = tf.train.AdamOptimizer(learning_rate=0.002,beta1=0.5)\n",
        "d_grads = trainerD.compute_gradients(d_loss,slim.get_variables(scope='discriminator'))\n",
        "g_grads = trainerG.compute_gradients(g_loss, slim.get_variables(scope='generator'))\n",
        "\n",
        "update_D = trainerD.apply_gradients(d_grads)\n",
        "update_G = trainerG.apply_gradients(g_grads)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "gH0wHswE_r71",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training the network\n"
      ]
    },
    {
      "metadata": {
        "id": "UdqKQegA_r74",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 4 #Size of image batch to apply at each iteration.\n",
        "iterations = 500000 #Total number of iterations to use.\n",
        "subset_size = 5000 #How many images to load at a time, will vary depending on available resources\n",
        "frame_directory = './frames' #Directory where training images are located\n",
        "sample_directory = './samples' #Directory to save sample images from generator in.\n",
        "model_directory = './model' #Directory to save trained model to.\n",
        "sample_frequency = 200 #How often to generate sample gif of translated images.\n",
        "save_frequency = 5000 #How often to save model.\n",
        "load_model = False #Whether to load the model or begin training from scratch."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "xXkqUmn6_r8B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "subset = 0\n",
        "dataS = sorted(glob(os.path.join(frame_directory, \"*.png\")))\n",
        "total_subsets = len(dataS)/subset_size\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "with tf.Session() as sess:  \n",
        "    sess.run(init)\n",
        "    if load_model == True: \n",
        "        ckpt = tf.train.get_checkpoint_state(model_directory)\n",
        "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
        "\n",
        "    imagesY,imagesX = loadImages(dataS[0:subset_size],False, np.random.randint(0,2)) #Load a subset of images\n",
        "    print \"Loaded subset \" + str(subset)\n",
        "    draw = range(len(imagesX))\n",
        "    for i in range(iterations):\n",
        "        if i % (subset_size/batch_size) != 0 or i == 0:\n",
        "            batch_index = np.random.choice(draw,size=batch_size,replace=False)\n",
        "        else:\n",
        "            subset = np.random.randint(0,total_subsets+1)\n",
        "            imagesY,imagesX = loadImages(dataS[subset*subset_size:(subset+1)*subset_size],False, np.random.randint(0,2))\n",
        "            print \"Loaded subset \" + str(subset)\n",
        "            draw = range(len(imagesX))\n",
        "            batch_index = np.random.choice(draw,size=batch_size,replace=False)\n",
        "        \n",
        "        ys = (np.reshape(imagesY[batch_index],[batch_size,height,width,3]) - 0.5) * 2.0 #Transform to be between -1 and 1\n",
        "        xs = (np.reshape(imagesX[batch_index],[batch_size,height,width,3]) - 0.5) * 2.0\n",
        "        _,dLoss = sess.run([update_D,d_loss],feed_dict={real_in:ys,condition_in:xs}) #Update the discriminator\n",
        "        _,gLoss = sess.run([update_G,g_loss],feed_dict={real_in:ys,condition_in:xs}) #Update the generator\n",
        "        if i % sample_frequency == 0:\n",
        "            print \"Gen Loss: \" + str(gLoss) + \" Disc Loss: \" + str(dLoss)\n",
        "            start_point = np.random.randint(0,len(imagesX)-32)\n",
        "            xs = (np.reshape(imagesX[start_point:start_point+32],[32,height,width,3]) - 0.5) * 2.0\n",
        "            ys = (np.reshape(imagesY[start_point:start_point+32],[32,height,width,3]) - 0.5) * 2.0\n",
        "            sample_G = sess.run(Gx,feed_dict={condition_in:xs}) #Use new z to get sample images from generator.\n",
        "            allS = np.concatenate([xs,sample_G,ys],axis=1)\n",
        "            if not os.path.exists(sample_directory):\n",
        "                os.makedirs(sample_directory)\n",
        "            #Save sample generator images for viewing training progress.\n",
        "            make_gif(allS,'./'+sample_directory+'/a_vid'+str(i)+'.gif',\n",
        "                duration=len(allS)*0.2,true_image=False)\n",
        "        if i % save_frequency == 0 and i != 0:\n",
        "            if not os.path.exists(model_directory):\n",
        "                os.makedirs(model_directory)\n",
        "            saver.save(sess,model_directory+'/model-'+str(i)+'.cptk')\n",
        "            print \"Saved Model\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u5U7Jm7d_r8L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Using a trained network"
      ]
    },
    {
      "metadata": {
        "id": "sBZBDLL5_r8N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_directory = '/content/gdrive/My Drive/pix2pix_images' #Directory to load test frames from\n",
        "subset_size = 5000\n",
        "batch_size = 60 # Size of image batch to apply at each iteration. Will depend of available resources.\n",
        "sample_directory = '/content/gdrive/My Drive/firegan' #Directory to save sample images from generator in.\n",
        "model_directory = '/content/gdrive/My Drive/model' #Directory to save trained model to.\n",
        "load_model = True #Whether to load a saved model."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1caEXyLlsiiD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "10cfefaa-2282-44f8-b35c-64d6ee4412f7"
      },
      "cell_type": "code",
      "source": [
        "print(sorted(glob(os.path.join(test_directory, \"*.png\"))))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/gdrive/My Drive/pix2pix_images/out0001.png', '/content/gdrive/My Drive/pix2pix_images/out0002.png', '/content/gdrive/My Drive/pix2pix_images/out0003.png', '/content/gdrive/My Drive/pix2pix_images/out0004.png', '/content/gdrive/My Drive/pix2pix_images/out0005.png', '/content/gdrive/My Drive/pix2pix_images/out0006.png', '/content/gdrive/My Drive/pix2pix_images/out0007.png', '/content/gdrive/My Drive/pix2pix_images/out0008.png', '/content/gdrive/My Drive/pix2pix_images/out0009.png', '/content/gdrive/My Drive/pix2pix_images/out0010.png', '/content/gdrive/My Drive/pix2pix_images/out0011.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rgMdlELS_r8W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "ac61d6fe-4256-4aa1-f9f4-a37786d5b169"
      },
      "cell_type": "code",
      "source": [
        "dataS = sorted(glob(os.path.join(test_directory, \"*.png\")))\n",
        "subset = 0\n",
        "total_subsets = len(dataS)/subset_size\n",
        "iterations = subset_size / batch_size #Total number of iterations to use.\n",
        "\n",
        "\n",
        "if not os.path.exists(sample_directory):\n",
        "    os.makedirs(sample_directory)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "with tf.Session() as sess:  \n",
        "    sess.run(init)\n",
        "    if load_model == True: \n",
        "        ckpt = tf.train.get_checkpoint_state(model_directory)\n",
        "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
        "        for s in range(total_subsets):\n",
        "            generated_frames = []\n",
        "            _,imagesX = loadImages(dataS[s*subset_size:s*subset_size+subset_size],False, False) #Load a subset of images\n",
        "            for i in range(iterations):\n",
        "                start_point = i * batch_size\n",
        "                xs = (np.reshape(imagesX[start_point:start_point+batch_size],[batch_size,height,width,3]) - 0.5) * 2.0\n",
        "                sample_G = sess.run(Gx,feed_dict={condition_in:xs}) #Use new z to get sample images from generator.    \n",
        "                #allS = np.concatenate([xs,sample_G],axis=2)\n",
        "                generated_frames.append(sample_G)\n",
        "            generated_frames = np.vstack(generated_frames)\n",
        "            for i in range(len(generated_frames)):\n",
        "                im = Image.fromarray(((generated_frames[i]/2.0 + 0.5) * 256).astype('uint8'))\n",
        "                im.save('./'+sample_directory+'/frame'+str(s*subset_size + i)+'.png')  \n",
        "            #make_gif(generated_frames,'./'+sample_directory+'/a_vid'+str(i)+'.gif',\n",
        "            #    duration=len(generated_frames)/10.0,true_image=False)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-47867266c7f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths, filename)\u001b[0m\n\u001b[1;32m    830\u001b[0m           time.time() + self._keep_checkpoint_every_n_hours * 3600)\n\u001b[1;32m    831\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use save/restore instead of build in eager mode.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self, checkpoint_path, build_save, build_restore)\u001b[0m\n\u001b[1;32m    867\u001b[0m           \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No variables to save\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No variables to save"
          ]
        }
      ]
    }
  ]
}